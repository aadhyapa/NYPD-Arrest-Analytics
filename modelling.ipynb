{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id, month, year, dayofweek,when, to_date, col\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace the placeholders with your actual values\n",
    "storage_account_name = <acount name>\n",
    "container_name = <container name>\n",
    "sas_token = <SAS Token>\n",
    "\n",
    "# Check if the directory is already mounted\n",
    "if not any(mount.mountPoint == f\"/mnt/{container_name}\" for mount in dbutils.fs.mounts()):\n",
    "    try:\n",
    "        dbutils.fs.mount(\n",
    "            source=f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/?{sas_token}\",\n",
    "            mount_point=f\"/mnt/{container_name}\",\n",
    "            extra_configs={f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\": sas_token}\n",
    "    )\n",
    "        print(\"Mount successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "# Additional error handling if needed\n",
    "else:\n",
    "    print(\"Directory already mounted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs \n",
    "ls \"/mnt/<container name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read a file from a mounted directory\n",
    "file_path = dbutils.fs.ls(\"/mnt/<container name>/raw_arrest_data\")\n",
    "\n",
    "df = spark.read.csv(\"/mnt/<container name>/raw_arrest_data\", header=True)\n",
    "display(df.limit(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()\n",
    "df = df.dropna()\n",
    "df = df.drop(col('New Georeferenced Column'))\n",
    "df = df.filter(col('ARREST_DATE').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['LAW_CAT_CD'].isin(['M', 'F', 'V']))\n",
    "df = df.filter(df['ARREST_BORO'].isin(['B', 'K', 'M', 'Q', 'S']))\n",
    "df = df.filter(df['PERP_SEX'].isin(['M', 'F']))\n",
    "df = df.withColumn('CASE_ID', monotonically_increasing_id())\n",
    "df = df.withColumn('ARREST_DATE', to_date('ARREST_DATE', 'MM/dd/yyyy'))\n",
    "display(df.limit(3))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_dim = df.select('CASE_ID', 'ARREST_KEY', 'ARREST_DATE', 'ARREST_BORO','ARREST_PRECINCT')\n",
    "\n",
    "arrest_dim = arrest_dim.withColumn('ARREST_ID', monotonically_increasing_id())\n",
    "#arrest_dim = arrest_dim.withColumn('ARREST_MONTH', month(col('ARREST_DATE')))\n",
    "arrest_dim = arrest_dim.withColumn('ARREST_YEAR', year(col('ARREST_DATE')))\n",
    "arrest_dim = arrest_dim.withColumn('ARREST_MONTH', month(col('ARREST_DATE')))\n",
    "arrest_dim = arrest_dim.withColumn('ARREST_WEEKDAY', dayofweek(col('ARREST_DATE')))\n",
    "\n",
    "arrest_dim = arrest_dim.withColumn('ARREST_BORO_NAME'\n",
    ",when(arrest_dim['ARREST_BORO'] == 'B', 'Bronx')\n",
    ".when(arrest_dim['ARREST_BORO'] == 'K', 'Brooklyn')\n",
    ".when(arrest_dim['ARREST_BORO'] == 'M', 'Manhattan')\n",
    ".when(arrest_dim['ARREST_BORO'] == 'Q', 'Queens')\n",
    ".when(arrest_dim['ARREST_BORO'] == 'S', 'Staten Island'))\n",
    "\n",
    "arrest_dim = arrest_dim[['ARREST_ID', 'CASE_ID', 'ARREST_KEY', 'ARREST_DATE', 'ARREST_MONTH', 'ARREST_YEAR', 'ARREST_WEEKDAY', 'ARREST_BORO', 'ARREST_BORO_NAME', 'ARREST_PRECINCT']]\n",
    "\n",
    "display(arrest_dim.limit(10))\n",
    "arrest_dim.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_dim = df.select('CASE_ID', 'PERP_SEX', 'PERP_RACE', 'AGE_GROUP')\n",
    "perp_dim = perp_dim.withColumn('PERP_ID', monotonically_increasing_id())\n",
    "perp_dim = perp_dim[['PERP_ID', 'CASE_ID', 'PERP_SEX', 'PERP_RACE', 'AGE_GROUP']]\n",
    "display(perp_dim.limit(3))\n",
    "perp_dim.count()\n",
    "display(perp_dim.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offence_dim = df.select('CASE_ID', 'OFNS_DESC', 'PD_DESC', 'PD_CD', 'KY_CD')\n",
    "offence_dim = offence_dim.withColumn('OFFENCE_ID', monotonically_increasing_id())\n",
    "offence_dim = offence_dim[['OFFENCE_ID', 'CASE_ID', 'OFNS_DESC', 'PD_DESC', 'PD_CD', 'KY_CD']]\n",
    "display(offence_dim.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dim = df.select('CASE_ID', 'X_COORD_CD', 'Y_COORD_CD', 'Latitude', 'Longitude')\n",
    "location_dim = location_dim.withColumn('LOCATION_ID', monotonically_increasing_id())\n",
    "location_dim = location_dim[['LOCATION_ID', 'CASE_ID', 'X_COORD_CD', 'Y_COORD_CD', 'Latitude', 'Longitude']]\n",
    "display(location_dim.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "law_dim = df.select('CASE_ID', 'LAW_CODE', 'LAW_CAT_CD')\n",
    "law_dim = law_dim.withColumn('LAW_ID', monotonically_increasing_id())\n",
    "law_dim = law_dim.withColumn('LAW_CODE_DESC'\n",
    ",when(law_dim['LAW_CAT_CD'] == 'F', 'Felony')\n",
    ".when(law_dim['LAW_CAT_CD'] == 'M', 'Misdemeanor')\n",
    ".when(law_dim['LAW_CAT_CD'] == 'V', 'Violation')\n",
    ")\n",
    "\n",
    "law_dim = law_dim[['LAW_ID', 'CASE_ID', 'LAW_CODE', 'LAW_CAT_CD', 'LAW_CODE_DESC']]\n",
    "display(law_dim.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juris_dim = df.select('CASE_ID', 'JURISDICTION_CODE')\n",
    "juris_dim = juris_dim.withColumn('JURISDICTION_ID', monotonically_increasing_id())\n",
    "juris_dim = juris_dim.withColumn('JURISDICTION_CODE_DESC'\n",
    ",when(juris_dim['JURISDICTION_CODE'] == 0, 'Patrol')\n",
    ".when(juris_dim['JURISDICTION_CODE'] == 1, 'Transit')\n",
    ".when(juris_dim['JURISDICTION_CODE'] == 2, 'Housing')\n",
    ".otherwise('Non NYPD')\n",
    ")\n",
    "\n",
    "juris_dim = juris_dim[['JURISDICTION_ID', 'CASE_ID', 'JURISDICTION_CODE', 'JURISDICTION_CODE_DESC']]\n",
    "display(juris_dim.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fact_table = df.alias(\"df\") \\\n",
    "    .join(arrest_dim.alias(\"arrest\"), col(\"df.ARREST_KEY\") == col(\"arrest.ARREST_KEY\"), 'inner') \\\n",
    "    .join(perp_dim.alias(\"perp\"), col(\"df.CASE_ID\") == col(\"perp.CASE_ID\"), 'inner') \\\n",
    "    .join(offence_dim.alias(\"offence\"), col(\"df.CASE_ID\") == col(\"offence.CASE_ID\"), 'inner') \\\n",
    "    .join(law_dim.alias(\"law\"), col(\"df.CASE_ID\") == col(\"law.CASE_ID\"), 'inner') \\\n",
    "    .join(location_dim.alias(\"location\"), col(\"df.CASE_ID\") == col(\"location.CASE_ID\"), 'inner') \\\n",
    "    .join(juris_dim.alias(\"juris\"), col(\"df.CASE_ID\") == col(\"juris.CASE_ID\"), 'inner') \\\n",
    "    .select(\n",
    "        col(\"df.CASE_ID\").alias(\"CASE_ID\"),\n",
    "        col(\"arrest.ARREST_ID\"),\n",
    "        col(\"perp.PERP_ID\"),\n",
    "        col(\"offence.OFFENCE_ID\"),\n",
    "        col(\"law.LAW_ID\"),\n",
    "        col(\"location.LOCATION_ID\"),\n",
    "        col(\"juris.JURISDICTION_ID\")\n",
    "    )\n",
    "\n",
    "display(fact_table.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs('/mnt/<container name>/transformed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write each DataFrame to its respective CSV file\n",
    "arrest_dim.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/arrest_dim.csv', header=True)\n",
    "perp_dim.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/perp_dim.csv', header=True)\n",
    "offence_dim.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/offence_dim.csv', header=True)\n",
    "law_dim.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/law_dim.csv', header=True)\n",
    "location_dim.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/location_dim.csv', header=True)\n",
    "juris_dim.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/juris_dim.csv', header=True)\n",
    "fact_table.write.mode('overwrite').csv('/mnt/<container name>/transformed_data/fact_table.csv', header=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
